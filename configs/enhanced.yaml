ppo:
  steps: 250e6
  win_bonus: 2.0
  partial_score: 1.0
  gamma: 0.999
  seq_rosteps: 128
  num_envs: 128
  num_self_play: 64
task:
  objective: "ENHANCED"
  enforce_unit_cap: true
  unit_cap: "step: 6@0 lin 20@50e6"
  adr: true
  rule_rng_fraction: 1.0
  rule_rng_amount: 1.0
  mothership_damage_scale: 0.0
eval:
  eval_frequency: 10e6
  #TODO: extra_checkpoint_steps: [1e6, 2.5e6]
  extra_checkpoint_steps: [1000000, 2500000]
  model_save_frequency: 1
  eval_envs: 128
  eval_frequency: 5e6
  eval_timesteps: 5000
optimizer:
  lr: "step: 0.0005@0 cos 0.00005@250e6"
  vf_coef: 1.0
  entropy_bonus: "step: 0.5@0 lin 0.15@20e6 0.0@200e6"
  batches_per_update: 4
  bs: 256
adr:
  variety: "step: 0.3@0 lin 0.15@150e6 0.1@200e6 0.01@250e6"
  cost_variance: "step: 2.0@0 lin 1.0@20e6 0.1@200e6"
  hstepsize: 2.5e-6
  linear_hardness: true
  max_hardness: 150
obs:
  allies: 20
  obs_map_tiles: 5
  obs_enemies: 20
  feat_last_seen: true
  feat_mineral_claims: true
  harvest_action: true
  feat_dist_to_wall: true
  obs_minerals: 5
policy:
  agents: 20
  nenemy: 20
  nally: 20
  nmineral: 5
  ntile: 5