Config(
    version: 4,
    optimizer: OptimizerConfig(
        lr: "step: 0.0015@0 cos 0.0003@5e6",
        weight_decay: 0.00007,
        batch_size: 512,
        micro_batch_size: 512,
        entropy_bonus: "step: 0.15@0 lin 0.15@2.5e6 0.0@5e6",
    ),
    eval: EvalConfig(
        envs: 128,
        steps: 1000,
        frequency: 500000,
        model_save_frequency: 1,
    ),
    ppo: PPOConfig(
        steps: 5000000,
        num_envs: 512,
        num_self_play: 256,
        seq_rosteps: 32,
        gamma: 0.9997,
        win_bonus: 2.0,
    ),
    task: TaskConfig(
        objective: "ARENA_MEDIUM",
        task_hardness: 1,
    ),
    adr: AdrConfig(
        initial_hardness: 1.0,
        linear_hardness: true,
        max_hardness: 1.0,
        hardness_offset: 1000000000000000.0,
    ),
    policy: PolicyConfig(
        agents: 8,
        nally: 8,
        nenemy: 8,
        nmineral: 8,
    ),
    obs: ObsConfig(
        allies: 8,
        obs_enemies: 8,
        obs_minerals: 8,
        obs_map_tiles: 0,
    ),
)