Config(
  version: 0,
  ppo: (
    steps: 5e6,
    win_bonus: 2.0,
    partial_score: 1.0,
    gamma: 0.9997,
    seq_rosteps: 32,
    num_envs: 512,
    num_self_play: 256
  ),
  adr: (
    initial_hardness: 1.0,
    max_hardness: 1.0,
    hardness_offset: 1e15,
    linear_hardness: true
  ),
  task: (
    objective: "ARENA_MEDIUM",
    task_hardness: 1
  ),
  eval: (
    eval_frequency: 500e3,
    model_save_frequency: 1,
    eval_envs: 128,
    eval_timesteps: 1000
  ),
  optimizer: (
    lr: "step: 0.0015@0 cos 0.0003@5e6",
    vf_coef: 1.0,
    entropy_bonus: "step: 0.15@0 lin 0.15@2.5e6 0.0@5e6",
    weight_decay: 7e-5,
    batch_size: 512,
    micro_batch_size: 512
  ),
  obs: (
    allies: 8,
    obs_enemies: 8,
    obs_minerals: 8,
    obs_map_tiles: 0
  ),
  policy: (
    agents: 8,
    nenemy: 8,
    nally: 8,
    nmineral: 8,
    ntile: 0
  ),
)